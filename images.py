# generation/images.py
from aiogram.exceptions import TelegramForbiddenError
import re
import aiohttp
import aiofiles
import uuid
import os
import logging
import time
import asyncio
import random
from typing import Optional, List, Dict, Tuple
from aiogram import Bot
from aiogram.types import Message, InputMediaPhoto, InlineKeyboardButton, InlineKeyboardMarkup, FSInputFile
from aiogram.fsm.context import FSMContext
from aiogram.enums import ParseMode
from aiogram.exceptions import TelegramBadRequest
import tenacity
import replicate
from replicate.exceptions import ReplicateError
from deep_translator import GoogleTranslator
from copy import deepcopy

from generation_config import (
    IMAGE_GENERATION_MODELS, ASPECT_RATIOS,
    GENERATION_TYPE_TO_MODEL_KEY, MULTI_LORA_MODEL, HF_LORA_MODELS, LORA_CONFIG, LORA_PRIORITIES, 
    LORA_STYLE_PRESETS, MAX_LORA_COUNT, USER_AVATAR_LORA_STRENGTH,
    CAMERA_SETUP_BASE, LUXURY_DETAILS_BASE
)
from config import MAX_FILE_SIZE_BYTES, REPLICATE_API_TOKEN, REPLICATE_USERNAME_OR_ORG_NAME, ADMIN_IDS
from database import (
    check_database_user, update_user_credits, get_active_trainedmodel, log_generation, check_user_resources
)
from keyboards import (
    create_main_menu_keyboard, create_rating_keyboard,
    create_subscription_keyboard, create_user_profile_keyboard, create_photo_generate_menu_keyboard
)
from generation.utils import (
    TempFileManager, reset_generation_context,
    send_message_with_fallback, send_photo_with_retry, send_media_group_with_retry
)
from llama_helper import generate_assisted_prompt
from handlers.utils import clean_admin_context, safe_escape_markdown as escape_md

user_last_generation_params = {}
user_last_generation_lock = asyncio.Lock()

logger = logging.getLogger(__name__)

# –£–í–ï–õ–ò–ß–ò–í–ê–ï–ú –õ–ò–ú–ò–¢–´ –î–õ–Ø 5000+ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô
MAX_CONCURRENT_GENERATIONS = 100
REPLICATE_RATE_LIMIT = 50
USER_GENERATION_COOLDOWN = 2

# –°–µ–º–∞—Ñ–æ—Ä—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
generation_semaphore = asyncio.Semaphore(MAX_CONCURRENT_GENERATIONS)
replicate_semaphore = asyncio.Semaphore(REPLICATE_RATE_LIMIT)
download_semaphore = asyncio.Semaphore(100)
file_operation_semaphore = asyncio.Semaphore(200)

# –ö—ç—à–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
active_models_cache = {}
cache_lock = asyncio.Lock()
user_last_generation = {}
user_generation_lock = {}

# –û—á–µ—Ä–µ–¥—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
generation_queue = asyncio.Queue(maxsize=1000)
queue_processor_running = False

# –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø LORA –î–õ–Ø –§–û–¢–û–†–ï–ê–õ–ò–ó–ú–ê
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–≤–µ–ª–∏—á–µ–Ω–∞ —Å–∏–ª–∞ –¥–ª—è skin_texture_master –¥–æ 1.0 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç—É—Ä—ã –∫–æ–∂–∏ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ –±–ª–µ—Å–∫–∞.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–≤–µ–ª–∏—á–µ–Ω–∞ —Å–∏–ª–∞ –¥–ª—è anti_cgi –¥–æ 1.0 –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è –±–æ—Ä—å–±—ã —Å CGI-—ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏ –∏ –ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–º –≤–∏–¥–æ–º.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–º–µ–Ω—å—à–µ–Ω–∞ —Å–∏–ª–∞ –¥–ª—è face_perfection_v2 –¥–æ 0.75, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —á—Ä–µ–∑–º–µ—Ä–Ω–æ–π –∏–¥–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–∏—Ü–∞, –¥–µ–ª–∞—è –µ–≥–æ –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–º–µ–Ω—å—à–µ–Ω–∞ —Å–∏–ª–∞ –¥–ª—è color_grading_pro –¥–æ 0.7 –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —á—Ä–µ–∑–º–µ—Ä–Ω–æ–π —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å –±–ª–µ—Å–∫.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–≤–µ–ª–∏—á–µ–Ω–∞ —Å–∏–ª–∞ –¥–ª—è ultra_details –¥–æ 0.85 –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ—Å—Ç–∏.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å "prithivMLmods/Flux-BetterSkin-LoRA" —Å —Å–∏–ª–æ–π 0.95 –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ–∫—Å—Ç—É—Ä—ã –∫–æ–∂–∏ –∏ —Å–Ω–∏–∂–µ–Ω–∏—è –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞.
ULTRA_PROFESSIONAL_LORA_CONFIG = {
    "photo_realism_pro": {
        "model": "alvdansen/frosting_lane_flux",
        "strength": 0.95,
        "keywords": ["photorealistic", "professional photo", "camera shot", "DSLR", "—Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π"],
        "description": "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ç–æ—Å—ä–µ–º–∫–∞",
        "priority": 1
    },
    "skin_texture_master": {
        "model": "prithivMLmods/Flux-Skin-Real",
        "strength": 1.0,
        "keywords": ["skin", "texture", "natural skin", "pores", "–∫–æ–∂–∞", "—Ç–µ–∫—Å—Ç—É—Ä–∞", "realistic skin"],
        "description": "–ù–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞ –∫–æ–∂–∏ –±–µ–∑ CGI —ç—Ñ—Ñ–µ–∫—Ç–∞",
        "priority": 2
    },
    "face_perfection_v2": {
        "model": "prithivMLmods/Canopus-LoRA-Flux-FaceRealism",
        "strength": 0.75,
        "keywords": ["face", "portrait", "eyes", "facial features", "–ª–∏—Ü–æ", "–≥–ª–∞–∑–∞"],
        "description": "–°–æ–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞ –∏ –≥–ª–∞–∑–∞",
        "priority": 3
    },
    "color_grading_pro": {
        "model": "renderartist/colorgrading",
        "strength": 0.7,
        "keywords": ["color grading", "cinematic", "professional lighting", "—Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è", "natural colors"],
        "description": "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è",
        "priority": 4
    },
    "ultra_details": {
        "model": "prithivMLmods/Flux-Realism-FineDetailed",
        "strength": 0.85,
        "keywords": ["detailed", "high detail", "ultra detailed", "–¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "fine details"],
        "description": "–£–ª—å—Ç—Ä–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è",
        "priority": 5
    },
    "anti_cgi": {
        "model": "https://huggingface.co/prithivMLmods/Flux-Dev-Real-Anime/resolve/main/Flux-Dev-Real-Anime.safetensors",
        "strength": 1.0,
        "keywords": ["real", "not cgi", "not 3d", "natural", "authentic", "—Ä–µ–∞–ª—å–Ω—ã–π"],
        "description": "–ê–Ω—Ç–∏-CGI —ç—Ñ—Ñ–µ–∫—Ç –¥–ª—è –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ—Å—Ç–∏",
        "priority": 6
    },
    "portrait_master_pro": {
        "model": "gokaygokay/Flux-Portrait-LoRA",
        "strength": 0.95,
        "keywords": ["portrait", "headshot", "professional portrait", "–ø–æ—Ä—Ç—Ä–µ—Ç"],
        "description": "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è",
        "priority": 7
    },
    "better_skin": {
        "model": "prithivMLmods/Flux-BetterSkin-LoRA",
        "strength": 0.95,
        "keywords": ["skin", "natural skin", "realistic skin"],
        "description": "–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è –∫–æ–∂–∞ –±–µ–∑ –±–ª–µ—Å–∫–∞",
        "priority": 8
    }
}

# –ü–†–ï–°–ï–¢–´ –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –§–û–¢–û–†–ï–ê–õ–ò–ó–ú–ê
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–ª—è –≤—Å–µ—Ö –ø—Ä–µ—Å–µ—Ç–æ–≤ —É–≤–µ–ª–∏—á–µ–Ω–æ num_inference_steps –¥–æ 60 –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Å–Ω–∏–∂–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£–º–µ–Ω—å—à–µ–Ω–æ guidance_scale –¥–æ 2.5-3.0 –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–µ—Ä–µ—É—Å–∏–ª–µ–Ω–∏—è.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω—ã LoRA "better_skin" –∏ "anti_cgi" –≤–æ –≤—Å–µ –ø—Ä–µ—Å–µ—Ç—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–∂–∏.
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ prompt_additions –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–º –±–ª–µ—Å–∫–æ–º: "matte skin finish, no shine, natural skin reflectance".
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º: "imperfect skin, natural variations in skin tone".
ULTRA_PHOTOREALISTIC_PRESETS = {
    "natural_portrait": {
        "loras": ["skin_texture_master", "photo_realism_pro", "face_perfection_v2", "anti_cgi", "better_skin"],
        "guidance_scale": 2.5,
        "num_inference_steps": 50,
        "prompt_additions": (
            "natural skin texture with visible pores, realistic skin tone, "
            "authentic human features, real person not CGI, "
            "soft natural lighting, candid expression, "
            "professional photography, DSLR quality, unretouched natural beauty, "
            "matte skin finish, no shine, natural skin reflectance, "
            "imperfect skin, natural variations in skin tone"
        )
    },
    "studio_perfection": {
        "loras": ["photo_realism_pro", "color_grading_pro", "face_perfection_v2", "ultra_details", "better_skin", "anti_cgi"],
        "guidance_scale": 3.0,
        "num_inference_steps": 50,
        "prompt_additions": (
            "professional studio photography, color corrected, natural skin tones, "
            "high-end commercial photography, realistic skin texture, "
            "professional lighting setup, authentic expression, "
            "magazine quality, shot on medium format camera, "
            "matte skin finish, no shine, natural skin reflectance, "
            "imperfect skin, natural variations in skin tone"
        )
    },
    "lifestyle_natural": {
        "loras": ["skin_texture_master", "anti_cgi", "photo_realism_pro", "portrait_master_pro", "better_skin"],
        "guidance_scale": 2.5,
        "num_inference_steps": 50,
        "prompt_additions": (
            "lifestyle photography, natural candid moment, "
            "real skin texture, authentic expression, natural lighting, "
            "photojournalism style, unposed, genuine emotion, "
            "shot with natural daylight, minimal retouching, "
            "matte skin finish, no shine, natural skin reflectance, "
            "imperfect skin, natural variations in skin tone"
        )
    }
}

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò –£–õ–£–ß–®–ï–ù–ù–´–ô NEGATIVE PROMPT
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø—Ä–æ—Ç–∏–≤ –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ –±–ª–µ—Å–∫–∞: "plastic shine, glossy skin, reflective skin, shiny pores, oily reflectance".
# –ò–∑–º–µ–Ω–µ–Ω–æ: –£—Å–∏–ª–µ–Ω—ã –∞–Ω—Ç–∏-CGI —ç–ª–µ–º–µ–Ω—Ç—ã: "cgi skin, rendered skin, artificial reflectance, fake shine".
# –ò–∑–º–µ–Ω–µ–Ω–æ: –î–æ–±–∞–≤–ª–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–µ–∞–ª–∏–∑–º–∞: "perfect symmetry, unnatural perfection, over-smoothed features".
ULTRA_NEGATIVE_PROMPT = (
    "3d render, cgi, computer graphics, digital art, artificial, fake, synthetic, "
    "unreal engine, blender, maya, 3ds max, rendered, digital painting, "
    "video game, animation, cartoon, anime, illustration, drawing, "
    "plastic skin, rubber skin, waxy skin, doll skin, mannequin skin, "
    "shiny skin, oily skin, greasy skin, artificial skin, smooth skin, "
    "perfect skin, flawless skin, airbrushed skin, retouched skin, "
    "red skin, pink skin, orange skin, yellow skin, purple skin, blue skin, "
    "oversaturated skin, desaturated skin, pale skin, colorless skin, "
    "wrong skin tone, unnatural skin color, artificial coloring, "
    "low quality, bad quality, worst quality, blurry, out of focus, "
    "pixelated, compression artifacts, jpeg artifacts, noise, grain, "
    "overexposed, underexposed, bad lighting, harsh lighting, "
    "bad anatomy, deformed face, asymmetric face, bad proportions, "
    "bad eyes, closed eyes, dead eyes, no pupils, weird eyes, "
    "bad hands, extra fingers, missing fingers, "
    "oversaturated, neon colors, artificial enhancement, heavy makeup, "
    "instagram filter, beauty filter, face tune, over-processed, "
    "watermark, text, logo, signature, frame, border, "
    "artificial lighting, neon lighting, fluorescent lighting, "
    "flat lighting, studio flash, harsh shadows, no shadows, "
    "plastic shine, glossy skin, reflective skin, shiny pores, oily reflectance, "
    "cgi skin, rendered skin, artificial reflectance, fake shine, "
    "perfect symmetry, unnatural perfection, over-smoothed features"
)

async def process_prompt_async(original_prompt: str, model_key: str, generation_type: str, 
                             trigger_word: str = None, selected_gender: str = None, 
                             user_input: str = None, user_data: Dict = None,
                             use_new_flux: bool = False) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –µ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π."""
    loop = asyncio.get_event_loop()
    
    def process_sync():
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞: original_prompt='{original_prompt[:50]}...', user_input='{user_input[:50] if user_input else None}...', "
                    f"generation_type={generation_type}, trigger_word={trigger_word}, selected_gender={selected_gender}")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ –∏ —ç—Ç–æ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if user_data.get('came_from_custom_prompt') and user_input:
            base_prompt = user_input
            logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç: {base_prompt[:50]}...")
        else:
            base_prompt = original_prompt
            logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {base_prompt[:50]}...")

        if generation_type == 'photo_to_photo':
            if use_new_flux and trigger_word:
                base = f"{trigger_word}, copy style from reference image"
                if base_prompt and base_prompt != "copy reference style":
                    base += f", {base_prompt}"
                return base + ", natural skin texture, realistic, photographic quality"
            elif trigger_word:
                return f"{trigger_word}, copy style from reference, natural realistic photo"
            else:
                return "copy reference image style, natural realistic photo, authentic"

        parts = []
        if trigger_word:
            parts.append(trigger_word)
        photorealistic_enhancers = [
            "professional photography",
            "photorealistic", 
            "real person",
            "natural skin texture with visible pores",
            "realistic skin tone",
            "authentic human features",
            "not CGI",
            "not 3D render",
            "DSLR camera quality",
            "natural expression",
            "genuine emotion",
            "sharp focus",
            "high resolution"
        ]
        # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–∏–ª–∏—Ç–µ–ª–∏ —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏–∑–º–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if not user_data.get('came_from_custom_prompt'):
            parts.extend(photorealistic_enhancers)
        if selected_gender:
            parts.append(selected_gender)
        parts.append(base_prompt)
        anti_cgi_details = (
            "shot with professional DSLR camera, natural daylight, "
            "real human skin with natural imperfections, "
            "unretouched authentic photography, photojournalism style, "
            "natural hair texture, realistic eye moisture, "
            "genuine facial expression, candid moment, "
            "no artificial enhancement, no beauty filters, "
            "raw unprocessed photo quality"
        )
        # –î–æ–±–∞–≤–ª—è–µ–º anti_cgi_details —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if not user_data.get('came_from_custom_prompt'):
            parts.append(anti_cgi_details)
        
        full_prompt = ", ".join(parts)
        full_prompt = re.sub(r'\s+', ' ', full_prompt).strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º
        if re.search('[–∞-—è–ê-–Ø]', full_prompt):
            try:
                translator = GoogleTranslator(source='auto', target='en')
                translated_prompt = translator.translate(full_prompt[:4500])
                if translated_prompt:
                    full_prompt = translated_prompt
                    logger.info(f"–ü—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π: {full_prompt[:50]}...")
                else:
                    logger.warning(f"–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {full_prompt[:50]}...")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞: {e}")
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞: {full_prompt[:50]}...")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞
        if len(full_prompt) > 4000:
            full_prompt = full_prompt[:4000].rsplit(', ', 1)[0]
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤: {full_prompt[:50]}...")
        
        return full_prompt
    
    return await loop.run_in_executor(None, process_sync)

async def prepare_model_params(use_new_flux: bool, model_key: str, generation_type: str,
                             prompt: str, num_outputs: int, aspect_ratio: str,
                             width: int, height: int, user_data: Dict) -> Optional[dict]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""
    logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: model_key={model_key}, generation_type={generation_type}, "
                f"prompt={prompt[:50]}..., aspect_ratio={aspect_ratio}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not isinstance(prompt, str):
        logger.error(f"–ü—Ä–æ–º–ø—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π: —Ç–∏–ø={type(prompt)}, –∑–Ω–∞—á–µ–Ω–∏–µ={prompt}")
        return None
    if not isinstance(aspect_ratio, str):
        logger.error(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π: —Ç–∏–ø={type(aspect_ratio)}, –∑–Ω–∞—á–µ–Ω–∏–µ={aspect_ratio}")
        return None
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ reference_image_url –Ω–∞ —Å–ª—É—á–∞–π –∫–æ—Ä—É—Ç–∏–Ω—ã
    reference_image_url = user_data.get('reference_image_url')
    if asyncio.iscoroutine(reference_image_url):
        logger.error(f"reference_image_url —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—É—Ç–∏–Ω–æ–π: {reference_image_url}")
        return None
    
    if use_new_flux:
        params = {
            "prompt": prompt,
            "model": "dev",
            "go_fast": True,
            "lora_scale": 1,
            "megapixels": "1",
            "num_outputs": num_outputs,
            "aspect_ratio": aspect_ratio,
            "output_format": "webp",
            "guidance_scale": 3.0,
            "output_quality": 100,
            "prompt_strength": 0.9,
            "num_inference_steps": 50
        }
        if generation_type == 'photo_to_photo':
            if not reference_image_url:
                logger.error("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç reference_image_url –¥–ª—è photo_to_photo")
                return None
            if not isinstance(reference_image_url, str):
                logger.error(f"reference_image_url –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π: —Ç–∏–ø={type(reference_image_url)}, –∑–Ω–∞—á–µ–Ω–∏–µ={reference_image_url}")
                return None
            params["image"] = reference_image_url
            params["prompt_strength"] = 0.8
            params["guidance_scale"] = 3.0
    elif model_key == "flux-trained":
        params = {
            "prompt": prompt,
            "num_outputs": num_outputs,
            "aspect_ratio": aspect_ratio,
            "lora_scale": 1,
            "output_format": "webp",
            "guidance_scale": 3.0,
            "width": width,
            "height": height,
            "scheduler": "DDIM",
            "prompt_strength": 0.8,
            "output_quality": 100,
            "num_inference_steps": 50
        }
        prompt_lower = prompt.lower()
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–µ—Å–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ù–ï –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if not user_data.get('came_from_custom_prompt'):
            if any(word in prompt_lower for word in ["natural", "candid", "authentic", "lifestyle"]):
                selected_preset = "lifestyle_natural"
            elif any(word in prompt_lower for word in ["studio", "professional", "commercial"]):
                selected_preset = "studio_perfection"
            else:
                selected_preset = "natural_portrait"
            if selected_preset in ULTRA_PHOTOREALISTIC_PRESETS:
                preset = ULTRA_PHOTOREALISTIC_PRESETS[selected_preset]
                params["guidance_scale"] = preset["guidance_scale"]
                params["num_inference_steps"] = preset["num_inference_steps"]
                params["prompt"] = f"{prompt}, {preset['prompt_additions']}"
                logger.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω –ø—Ä–µ—Å–µ—Ç {selected_preset} —Å –¥–æ–±–∞–≤–∫–∞–º–∏: {preset['prompt_additions'][:50]}...")
        else:
            logger.info(f"–ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –ø—Ä–µ—Å–µ—Ç –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è: {prompt[:50]}...")
        
        lora_index = 1
        if generation_type in ['with_avatar', 'photo_to_photo']:
            trigger_word = user_data.get('trigger_word')
            old_model_id = user_data.get('old_model_id')
            old_model_version = user_data.get('old_model_version')
            if trigger_word and old_model_version:
                if old_model_id:
                    if '/' not in old_model_id:
                        avatar_lora = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{old_model_id}:{old_model_version}"
                    else:
                        avatar_lora = f"{old_model_id}:{old_model_version}"
                    params[f"hf_lora_{lora_index}"] = avatar_lora
                    params[f"lora_scale_{lora_index}"] = 0.99
                    lora_index += 1
                    logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π LoRA —Å —Å–∏–ª–æ–π 0.9")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ LoRA —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ù–ï –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if not user_data.get('came_from_custom_prompt'):
            preset_loras = ULTRA_PHOTOREALISTIC_PRESETS.get(selected_preset, {}).get("loras", [])
            for lora_name in preset_loras:
                if lora_index <= MAX_LORA_COUNT and lora_name in ULTRA_PROFESSIONAL_LORA_CONFIG:
                    lora_cfg = ULTRA_PROFESSIONAL_LORA_CONFIG[lora_name]
                    params[f"hf_lora_{lora_index}"] = lora_cfg["model"]
                    params[f"lora_scale_{lora_index}"] = lora_cfg["strength"]
                    logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π LoRA {lora_name} –Ω–∞ –ø–æ–∑–∏—Ü–∏—é {lora_index}: strength={lora_cfg['strength']}")
                    lora_index += 1
        
        # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º anti_cgi LoRA, –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ
        anti_cgi_added = any(
            "Flux-Dev-Real-Anime" in params.get(f"hf_lora_{i}", "") 
            for i in range(1, lora_index)
        )
        if not anti_cgi_added and lora_index <= MAX_LORA_COUNT:
            anti_cgi_cfg = ULTRA_PROFESSIONAL_LORA_CONFIG["anti_cgi"]
            params[f"hf_lora_{lora_index}"] = anti_cgi_cfg["model"]
            params[f"lora_scale_{lora_index}"] = anti_cgi_cfg["strength"]
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω Anti-CGI LoRA –Ω–∞ –ø–æ–∑–∏—Ü–∏—é {lora_index}")
        
        params["negative_prompt"] = ULTRA_NEGATIVE_PROMPT
        if generation_type == 'photo_to_photo':
            if not reference_image_url:
                logger.error("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç reference_image_url –¥–ª—è photo_to_photo")
                return None
            if not isinstance(reference_image_url, str):
                logger.error(f"reference_image_url –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π: —Ç–∏–ø={type(reference_image_url)}, –∑–Ω–∞—á–µ–Ω–∏–µ={reference_image_url}")
                return None
            params["image"] = reference_image_url
            params["strength"] = 0.75
        
        logger.info(f"=== ULTRA REALISTIC PARAMETERS ===")
        logger.info(f"Preset: {selected_preset if not user_data.get('came_from_custom_prompt') else 'none (custom prompt)'}")
        logger.info(f"Guidance Scale: {params['guidance_scale']}")
        logger.info(f"Inference Steps: {params['num_inference_steps']}")
        logger.info(f"Total Professional LoRAs: {lora_index - 1}")
        logger.info(f"Anti-CGI enabled: {anti_cgi_added}")
        logger.info(f"Final prompt: {params['prompt'][:50]}...")
    
    else:
        params = {
            "prompt": prompt,
            "num_outputs": num_outputs,
            "aspect_ratio": aspect_ratio,
            "output_format": "webp",
            "guidance_scale": 2.0,
            "num_inference_steps": 50,
            "width": width,
            "height": height
        }
    
    logger.info(f"–í–æ–∑–≤—Ä–∞—â–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {params}")
    return params

async def start_queue_processor():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    global queue_processor_running
    if not queue_processor_running:
        queue_processor_running = True
        for i in range(20):
            asyncio.create_task(process_generation_queue(i))
        logger.info("–ó–∞–ø—É—â–µ–Ω—ã –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π")

async def process_generation_queue(worker_id: int):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    while True:
        try:
            task = await generation_queue.get()
            if task is None:
                break
            message, state, num_outputs = task
            try:
                await _generate_image_internal(message, state, num_outputs)
            except Exception as e:
                logger.error(f"Worker {worker_id}: –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}", exc_info=True)
            finally:
                generation_queue.task_done()
        except Exception as e:
            logger.error(f"Worker {worker_id}: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—á–µ—Ä–µ–¥–∏: {e}", exc_info=True)
            await asyncio.sleep(1)

async def get_user_generation_lock(user_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_generation_lock:
        user_generation_lock[user_id] = asyncio.Lock()
    return user_generation_lock[user_id]

async def check_user_cooldown(user_id: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å (cooldown)"""
    last_time = user_last_generation.get(user_id, 0)
    current_time = time.time()
    if current_time - last_time < USER_GENERATION_COOLDOWN:
        return False
    user_last_generation[user_id] = current_time
    return True

async def get_active_model_cached(user_id: int):
    
    async with cache_lock:
        if user_id in active_models_cache:
            cache_time, model_data = active_models_cache[user_id]
            if time.time() - cache_time < 300:
                return model_data
    model_data = await get_active_trainedmodel(user_id)
    async with cache_lock:
        active_models_cache[user_id] = (time.time(), model_data)
        if len(active_models_cache) > 1000:
            oldest_users = sorted(active_models_cache.items(), key=lambda x: x[1][0])[:100]
            for old_user_id, _ in oldest_users:
                del active_models_cache[old_user_id]
    return model_data

async def download_image_async(session: aiohttp.ClientSession, url: str, filepath: str, retry_count: int = 3) -> Optional[str]:
    
    async with download_semaphore:
        for attempt in range(retry_count):
            try:
                timeout = aiohttp.ClientTimeout(total=30)
                async with session.get(url, timeout=timeout) as response:
                    if response.status == 200:
                        os.makedirs(os.path.dirname(filepath), exist_ok=True)
                        async with aiofiles.open(filepath, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                await f.write(chunk)
                        logger.debug(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {filepath}")
                        return filepath
                    else:
                        logger.warning(f"HTTP {response.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            except asyncio.TimeoutError:
                logger.warning(f"–¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retry_count}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retry_count}: {e}")
            if attempt < retry_count - 1:
                await asyncio.sleep(1 * (attempt + 1))
        return None

async def download_images_parallel(urls: List[str], user_id: int) -> List[str]:
   
    paths = []
    tasks = []
    connector = aiohttp.TCPConnector(limit=20, limit_per_host=10)
    timeout = aiohttp.ClientTimeout(total=60)
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        for i, url in enumerate(urls):
            filepath = f"generated/{user_id}_{uuid.uuid4().hex[:8]}_{i}.png"
            task = download_image_async(session, url, filepath)
            tasks.append(task)
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for result in results:
            if isinstance(result, str) and result:
                paths.append(result)
            elif isinstance(result, Exception):
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {result}")
    return paths

async def generate_image(message: Message, state: FSMContext, num_outputs: int = 2, user_id: int = None) -> None:
   
    user_data = await state.get_data()
    bot = message.bot
    bot_id = (await bot.get_me()).id
    user_id = user_id or message.from_user.id

    logger.info(f"=== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–ê–ß–ê–õ–ê–°–¨ ===")
    logger.info(f"–ò–Ω–∏—Ü–∏–∞—Ç–æ—Ä: {user_id}")
    logger.info(f"user_data –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {user_data}")

    is_admin_generation = user_data.get('is_admin_generation', False)
    admin_generation_for_user = user_data.get('admin_generation_for_user')
    admin_user_id = user_data.get('original_admin_user', user_id)

    if is_admin_generation and admin_generation_for_user and user_id in ADMIN_IDS:
        message_recipient = admin_user_id
        target_user_id = admin_generation_for_user
        if target_user_id == bot_id:
            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π target_user_id: {target_user_id} (ID –±–æ—Ç–∞)")
            await send_message_with_fallback(
                bot, admin_user_id,
                escape_md("‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", version=2),
                reply_markup=await create_main_menu_keyboard(admin_user_id),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return
        logger.info(f"–ê–î–ú–ò–ù–°–ö–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø: –∞–¥–º–∏–Ω={message_recipient}, —Ü–µ–ª—å={target_user_id}")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        trained_model_data = await get_active_model_cached(target_user_id)
        if trained_model_data and trained_model_data[3] == 'success':
            await state.update_data(
                trigger_word=trained_model_data[5],
                model_version=trained_model_data[2],
                old_model_id=trained_model_data[4],
                old_model_version=trained_model_data[0],
                active_avatar_name=trained_model_data[8]
            )
        else:
            logger.error(f"–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è target_user_id={target_user_id}")
            await send_message_with_fallback(
                bot, admin_user_id,
                escape_md(f"‚ùå –£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ID `{target_user_id}` –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞.", version=2),
                reply_markup=InlineKeyboardMarkup(inline_keyboard=[
                    [InlineKeyboardButton(text="üîô –ö –¥–µ–π—Å—Ç–≤–∏—è–º", callback_data=f"user_actions_{target_user_id}")]
                ]),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return
    else:
        message_recipient = user_id
        target_user_id = user_id
        logger.info(f"–û–ë–´–ß–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å={target_user_id}")
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–¥–º–∏–Ω—Å–∫–∏–µ –ø–æ–ª—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—ã—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        admin_fields = [
            'is_admin_generation', 'admin_generation_for_user', 
            'admin_target_user_id', 'giving_sub_to_user',
            'broadcast_type', 'awaiting_broadcast_message',
            'awaiting_search_query', 'admin_view_source'
        ]
        await state.update_data({field: None for field in admin_fields})

    required_fields = ['prompt', 'aspect_ratio', 'generation_type', 'model_key']
    missing_fields = []
    empty_fields = []

    logger.info(f"=== –î–ï–¢–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• ===")
    for field in required_fields:
        value = user_data.get(field)
        logger.info(f"–ü–æ–ª–µ '{field}': –∫–ª—é—á_—Å—É—â–µ—Å—Ç–≤—É–µ—Ç={field in user_data}, –∑–Ω–∞—á–µ–Ω–∏–µ='{value}', —Ç–∏–ø={type(value)}")
        if field not in user_data:
            missing_fields.append(field)
        elif value is None or value == '' or value == 'None' or (isinstance(value, str) and not value.strip()):
            empty_fields.append(field)

    problem_fields = missing_fields + empty_fields
    if problem_fields:
        logger.error(f"–ü–†–û–ë–õ–ï–ú–ê: –ø–æ–ª—è {problem_fields} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏–ª–∏ –ø—É—Å—Ç—ã")
        logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏: {missing_fields}")
        logger.error(f"–ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {empty_fields}")
        recovery_attempted = False
        if 'generation_type' in problem_fields and not user_data.get('generation_type'):
            if user_data.get('current_style_set') in ['new_male_avatar', 'new_female_avatar', 'generic_avatar']:
                await state.update_data(generation_type='with_avatar')
                logger.info("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω generation_type = 'with_avatar'")
                recovery_attempted = True
            elif user_data.get('reference_image_url') or user_data.get('photo_path'):
                await state.update_data(generation_type='photo_to_photo')
                logger.info("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω generation_type = 'photo_to_photo'")
                recovery_attempted = True
        if 'model_key' in problem_fields and not user_data.get('model_key'):
            gen_type = user_data.get('generation_type')
            if gen_type in ['with_avatar', 'photo_to_photo']:
                await state.update_data(model_key='flux-trained')
                logger.info("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω model_key = 'flux-trained'")
                recovery_attempted = True
        if recovery_attempted:
            user_data = await state.get_data()
            final_missing = [f for f in required_fields if f not in user_data or not user_data.get(f)]
            if not final_missing:
                logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
            else:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å: {final_missing}")
                await send_message_with_fallback(
                    bot, message_recipient,
                    f"‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö: {', '.join(final_missing)}. –ù–∞—á–Ω–∏ –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ /menu.",
                    reply_markup=await create_main_menu_keyboard(message_recipient),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
                return
        else:
            await send_message_with_fallback(
                bot, message_recipient,
                f"‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö: {', '.join(problem_fields)}. –ù–∞—á–Ω–∏ –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ /menu.",
                reply_markup=await create_main_menu_keyboard(message_recipient),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return

    await start_queue_processor()
    if not await check_user_cooldown(message_recipient):
        await send_message_with_fallback(
            bot, message_recipient,
            "‚è≥ –ü–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π!",
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return

    generation_type = user_data.get('generation_type')
    if generation_type == 'with_avatar':
        required_photos = num_outputs
    elif generation_type == 'photo_to_photo':
        required_photos = 2
    else:
        required_photos = 1

    if not is_admin_generation:
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è user_id={target_user_id}, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–æ—Ç–æ: {required_photos}")
        if not await check_user_resources(bot, target_user_id, required_photos=required_photos):
            return

    if generation_queue.full():
        await send_message_with_fallback(
            bot, message_recipient,
            "üòî –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω! –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )
        return

    try:
        generation_data = deepcopy({
            'prompt': user_data.get('prompt'),
            'aspect_ratio': user_data.get('aspect_ratio'),
            'generation_type': user_data.get('generation_type'),
            'model_key': user_data.get('model_key'),
            'selected_gender': user_data.get('selected_gender'),
            'user_input_for_llama': user_data.get('user_input_for_llama'),
            'trigger_word': user_data.get('trigger_word'),
            'model_version': user_data.get('model_version'),
            'old_model_id': user_data.get('old_model_id'),
            'old_model_version': user_data.get('old_model_version'),
            'reference_image_url': user_data.get('reference_image_url'),
            'photo_path': user_data.get('photo_path'),
            'message_recipient': message_recipient,
            'generation_target_user': target_user_id,
            'original_admin_user': admin_user_id,
            'is_admin_generation': is_admin_generation,
            'admin_generation_for_user': admin_generation_for_user,
            'photos_to_deduct': required_photos if not is_admin_generation else 0,
            'current_style_set': user_data.get('current_style_set'),
            'came_from_custom_prompt': user_data.get('came_from_custom_prompt', False),
            'use_llama_prompt': user_data.get('use_llama_prompt', False),
            'last_generation_params': user_data.get('last_generation_params'),
            'active_avatar_name': user_data.get('active_avatar_name')
        })
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—á–µ—Ä–µ–¥–∏: {list(generation_data.keys())}")
        logger.info(f"generation_type: '{generation_data['generation_type']}'")
        logger.info(f"model_key: '{generation_data['model_key']}'")
        logger.info(f"prompt: '{generation_data['prompt'][:50]}...' (–æ–±—Ä–µ–∑–∞–Ω)" if generation_data.get('prompt') else "prompt: None")
        critical_fields = ['prompt', 'aspect_ratio', 'generation_type', 'model_key']
        missing_in_saved = [f for f in critical_fields if not generation_data.get(f)]
        if missing_in_saved:
            logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –¥–∞–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä—è–Ω—ã –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {missing_in_saved}")
            logger.error(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ user_data: {user_data}")
            await send_message_with_fallback(
                bot, message_recipient,
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {', '.join(missing_in_saved)}. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á–µ—Ä–µ–∑ /menu.",
                reply_markup=await create_main_menu_keyboard(message_recipient),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            return
        await state.update_data(generation_data)
        logger.info(f"–ü–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ –æ—á–µ—Ä–µ–¥—å: user_data={user_data}")
        await generation_queue.put((message, state, num_outputs))
        queue_size = generation_queue.qsize()
        if queue_size > 10:
            if is_admin_generation:
                message_text = f"üìä –ó–∞–ø—Ä–æ—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {target_user_id} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å (–ø–æ–∑–∏—Ü–∏—è: ~{queue_size})."
            else:
                message_text = f"üìä –¢–≤–æ–π –∑–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å (–ø–æ–∑–∏—Ü–∏—è: ~{queue_size}). –û–∂–∏–¥–∞–π —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è!"
            await send_message_with_fallback(
                bot, message_recipient,
                message_text,
                parse_mode=ParseMode.MARKDOWN_V2
            )
        logger.info(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å: recipient={message_recipient}, target={target_user_id}, is_admin={is_admin_generation}, queue_size={queue_size}")
    except asyncio.QueueFull:
        logger.error(f"–û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è user_id={message_recipient}")
        await send_message_with_fallback(
            bot, message_recipient,
            "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑!",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )
    except Exception as e:
        logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ generate_image –¥–ª—è user_id={message_recipient}: {e}", exc_info=True)
        await send_message_with_fallback(
            bot, message_recipient,
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )

async def _generate_image_internal(message: Message, state: FSMContext, num_outputs: int = 2) -> None:
    """
    –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —É–ª—å—Ç—Ä–∞-—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    """
    from handlers.generation import handle_admin_generation_result

    async with asyncio.Lock():
        user_data = await state.get_data()
        message_recipient = user_data.get('message_recipient', message.from_user.id)
        target_user_id = user_data.get('generation_target_user', message.from_user.id)
        admin_user_id = user_data.get('original_admin_user', message.from_user.id)
        is_admin_generation = user_data.get('is_admin_generation', False)
        bot = message.bot
        bot_id = (await bot.get_me()).id

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º preserved_data –ø—É—Å—Ç—ã–º —Å–ª–æ–≤–∞—Ä–µ–º
        preserved_data = {}

        if message_recipient == bot_id or target_user_id == bot_id:
            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID –ø–æ–ª—É—á–∞—Ç–µ–ª—è –∏–ª–∏ —Ü–µ–ª–∏: message_recipient={message_recipient}, target_user_id={target_user_id}, bot_id={bot_id}")
            return

        logger.info(f"=== –í–ù–£–¢–†–ï–ù–ù–Ø–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø ===")
        logger.info(f"message_recipient={message_recipient}, target_user_id={target_user_id}, admin_user_id={admin_user_id}")
        logger.info(f"is_admin_generation={is_admin_generation}")
        logger.info(f"–î–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: user_data={user_data}")

        start_time = time.time()
        user_lock = await get_user_generation_lock(target_user_id)

        async with user_lock:
            async with generation_semaphore:
                logger.info(f"üéØ –£–õ–¨–¢–†–ê-–†–ï–ê–õ–ò–°–¢–ò–ß–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –¥–ª—è user_id={target_user_id}" + 
                           (f" (–∞–¥–º–∏–Ω: {admin_user_id})" if is_admin_generation else ""))
                
                subscription_data = await check_database_user(target_user_id)
                if not isinstance(subscription_data, tuple) or len(subscription_data) < 9:
                    logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è user_id={target_user_id}: {subscription_data}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞! –ü–æ–ø—Ä–æ–±—É–π /menu.", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    return
                
                generation_type = user_data.get('generation_type')
                prompt = user_data.get('prompt')
                aspect_ratio_key = user_data.get('aspect_ratio')
                model_key = user_data.get('model_key')
                style_name = user_data.get('style_name', '–ö–∞—Å—Ç–æ–º–Ω—ã–π —Å—Ç–∏–ª—å')

                logger.info(f"=== –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• –í–û –í–ù–£–¢–†–ï–ù–ù–ï–ô –§–£–ù–ö–¶–ò–ò ===")
                logger.info(f"generation_type: '{generation_type}' (—Ç–∏–ø: {type(generation_type)})")
                logger.info(f"prompt: '{prompt[:50] if prompt else None}...' (—Ç–∏–ø: {type(prompt)})")
                logger.info(f"aspect_ratio_key: '{aspect_ratio_key}' (—Ç–∏–ø: {type(aspect_ratio_key)})")
                logger.info(f"model_key: '{model_key}' (—Ç–∏–ø: {type(model_key)})")

                missing_critical = []
                if not generation_type or generation_type == 'None':
                    missing_critical.append('generation_type')
                if not prompt or prompt == 'None':
                    missing_critical.append('prompt')
                if not aspect_ratio_key or aspect_ratio_key == 'None':
                    missing_critical.append('aspect_ratio')
                if not model_key or model_key == 'None':
                    missing_critical.append('model_key')
                
                if missing_critical:
                    logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Ñ—É–Ω–∫—Ü–∏–∏!")
                    logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è: {missing_critical}")
                    logger.error(f"–í—Å–µ –¥–∞–Ω–Ω—ã–µ user_data: {user_data}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ù–∞—á–Ω–∏ –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ /menu.", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    return
                
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if not trained_model_data or trained_model_data[3] != 'success':
                        logger.error(f"–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è target_user_id={target_user_id}")
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –ê–∫—Ç–∏–≤–Ω—ã–π –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤! –°–æ–∑–¥–∞–π –µ–≥–æ –≤ –õ–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ.", version=2),
                            reply_markup=await create_user_profile_keyboard(message_recipient, bot),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return
                
                required_photos = user_data.get('photos_to_deduct', num_outputs)
                
                if not is_admin_generation:
                    logger.info(f"–°–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è user_id={target_user_id}, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–æ—Ç–æ: {required_photos}")
                    await update_user_credits(target_user_id, "decrement_photo", amount=required_photos)
                    logger.info(f"–°–ø–∏—Å–∞–Ω–æ {required_photos} —Ñ–æ—Ç–æ –¥–ª—è user_id={target_user_id}")
                
                selected_gender = user_data.get('selected_gender')
                user_input_for_helper = user_data.get('user_input_for_llama')
                
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if trained_model_data and trained_model_data[3] == 'success':
                        await state.update_data(
                            trigger_word=trained_model_data[5],
                            model_version=trained_model_data[2],
                            old_model_id=trained_model_data[4],
                            old_model_version=trained_model_data[0],
                            active_avatar_name=trained_model_data[8]
                        )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π
                generation_params = {
                    'prompt': prompt,
                    'aspect_ratio': aspect_ratio_key,
                    'generation_type': generation_type,
                    'model_key': model_key,
                    'selected_gender': selected_gender,
                    'user_input_for_llama': user_input_for_helper,
                    'style_name': style_name,
                    'current_style_set': user_data.get('current_style_set'),
                    'came_from_custom_prompt': user_data.get('came_from_custom_prompt', False),
                    'use_llama_prompt': user_data.get('use_llama_prompt', False),
                    'duration': 0.0
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º last_generation_params –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                preserved_data['last_generation_params'] = generation_params
                
                if model_key not in IMAGE_GENERATION_MODELS:
                    logger.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π model_key: {model_key}")
                    await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏!", version=2),
                        reply_markup=await create_main_menu_keyboard(message_recipient),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                    await reset_generation_context(state, generation_type)
                    return
                
                model_config = IMAGE_GENERATION_MODELS[model_key]
                replicate_model_id_to_run = model_config['id']
                trigger_word = user_data.get('trigger_word')
                use_new_flux_method = False
                
                if generation_type in ['with_avatar', 'photo_to_photo']:
                    trained_model_data = await get_active_model_cached(target_user_id)
                    if not trained_model_data or trained_model_data[3] != 'success':
                        logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏!")
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –∞–≤–∞—Ç–∞—Ä –Ω–µ –≥–æ—Ç–æ–≤!", version=2),
                            reply_markup=await create_user_profile_keyboard(message_recipient, bot),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return
                    avatar_id, model_id, model_version, status, prediction_id, trigger_word, photo_paths, training_step, avatar_name = trained_model_data
                    await state.update_data(trigger_word=trigger_word, model_version=model_version, active_avatar_name=avatar_name)
                    logger.info(f"Active avatar for user {target_user_id}: {avatar_name} (ID: {avatar_id})")
                    logger.info(f"Avatar model_id: {model_id}")
                    logger.info(f"Avatar model_version: {model_version}")
                    is_fast_flux = is_new_fast_flux_model(model_id, model_version)
                    if is_fast_flux:
                        use_new_flux_method = True
                        if model_version:
                            if '/' not in model_id:
                                replicate_model_id_to_run = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{model_id}:{model_version}"
                            else:
                                replicate_model_id_to_run = f"{model_id}:{model_version}"
                        else:
                            if '/' not in model_id:
                                replicate_model_id_to_run = f"{REPLICATE_USERNAME_OR_ORG_NAME}/{model_id}"
                            else:
                                replicate_model_id_to_run = model_id
                        logger.info(f"Using Fast Flux model: {replicate_model_id_to_run}")
                    else:
                        use_new_flux_method = False
                        replicate_model_id_to_run = MULTI_LORA_MODEL
                        logger.info(f"Using Multi-LoRA model for old avatar: {replicate_model_id_to_run}")
                        await state.update_data(old_model_id=model_id, old_model_version=model_version)
                
                generation_message = await send_message_with_fallback(
                    bot, message_recipient,
                    escape_md(f"üì∏ –°–æ–∑–¥–∞—é {num_outputs} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ! –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞...", version=2),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
                
                if not isinstance(generation_message, Message):
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è user_id={message_recipient}, generation_message={generation_message}")
                    generation_message = await send_message_with_fallback(
                        bot, message_recipient,
                        escape_md("üì∏ –°–æ–∑–¥–∞—é —Ñ–æ—Ç–æ... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.", version=2),
                        parse_mode=ParseMode.MARKDOWN_V2
                    )
                
                try:
                    user_data = await state.get_data()
                    processed_prompt = await process_prompt_async(
                        prompt, model_key, generation_type,
                        trigger_word, selected_gender, user_input_for_helper, user_data,
                        use_new_flux=use_new_flux_method
                    )
                    width, height = ASPECT_RATIOS.get(aspect_ratio_key, (1440, 1440))
                    input_params = await prepare_model_params(
                        use_new_flux_method, model_key, generation_type,
                        processed_prompt, num_outputs, aspect_ratio_key,
                        width, height, user_data
                    )
                    if input_params is None:
                        if isinstance(generation_message, Message):
                            await generation_message.delete()
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤!", version=2),
                            reply_markup=await create_main_menu_keyboard(message_recipient),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ input_params —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
                    if not isinstance(input_params, dict):
                        logger.error(f"input_params –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º: —Ç–∏–ø={type(input_params)}, –∑–Ω–∞—á–µ–Ω–∏–µ={input_params}")
                        if isinstance(generation_message, Message):
                            await generation_message.delete()
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏!", version=2),
                            reply_markup=await create_main_menu_keyboard(message_recipient),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        await reset_generation_context(state, generation_type)
                        return
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º Replicate
                    logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Replicate: {input_params}")
                    
                    await log_generation(
                        target_user_id,
                        generation_type,
                        replicate_model_id_to_run,
                        num_outputs
                    )
                    
                    if isinstance(generation_message, Message):
                        await generation_message.edit_text(
                            escape_md(
                                f"üéØ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∞—à–∏ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é PixelPie_AI.\n"
                                f"üì∏ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –ò–ò –Ω–µ–π—Ä–æ—Å–µ—Ç—å!\n"
                                f"‚ö° PixelPie_AI —Å–æ–∑–¥–∞–µ—Ç –≤–∞—à —à–µ–¥–µ–≤—Ä!", version=2
                            ),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                    
                    async with replicate_semaphore:
                        image_urls = await run_replicate_model_async(replicate_model_id_to_run, input_params)
                    
                    if not image_urls:
                        logger.error("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Replicate")
                        if isinstance(generation_message, Message):
                            await generation_message.edit_text(
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏! –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        else:
                            await send_message_with_fallback(
                                bot, message_recipient,
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏! –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        await reset_generation_context(state, generation_type)
                        return
                    
                    if isinstance(generation_message, Message):
                        await generation_message.edit_text(
                            escape_md("‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–∞–≥—Ä—É–∂–∞—é –≥–æ—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...", version=2),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                    else:
                        await send_message_with_fallback(
                            bot, message_recipient,
                            escape_md("‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–∞–≥—Ä—É–∂–∞—é –≥–æ—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...", version=2),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                    
                    image_paths = await download_images_parallel(image_urls, target_user_id)
                    if not image_paths:
                        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        if isinstance(generation_message, Message):
                            await generation_message.edit_text(
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏! –ü–µ—á–µ–Ω—å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        else:
                            await send_message_with_fallback(
                                bot, message_recipient,
                                escape_md("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏! –ü–µ—á–µ–Ω—å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã.", version=2),
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        if not is_admin_generation:
                            await update_user_credits(target_user_id, "increment_photo", amount=required_photos)
                            logger.info(f"–§–æ—Ç–æ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å –¥–ª—è user_id={target_user_id}")
                        await reset_generation_context(state, generation_type)
                        return
                    
                    duration = time.time() - start_time
                    try:
                        if isinstance(generation_message, Message):
                            await generation_message.delete()
                    except:
                        pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º last_generation_params —Å image_urls –∏ duration
                    generation_params.update({'image_urls': image_urls, 'duration': duration})
                    preserved_data.update({
                        'last_generation_params': generation_params,
                    })
                    if is_admin_generation:
                        last_gen = user_data.get(f'last_admin_generation_{target_user_id}', {})
                        last_gen.update({'image_urls': image_urls, 'duration': duration})
                        preserved_data.update({
                            'is_admin_generation': True,
                            'admin_generation_for_user': target_user_id,
                            'message_recipient': admin_user_id,
                            'generation_target_user': target_user_id,
                            'original_admin_user': admin_user_id,
                            f'last_admin_generation_{target_user_id}': last_gen
                        })
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    await state.update_data(**preserved_data)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                    if is_admin_generation:
                        result_data = {
                            'success': True,
                            'image_urls': image_urls,
                            'prompt': processed_prompt,
                            'style': user_data.get('style_name', 'custom')
                        }
                        await handle_admin_generation_result(state, admin_user_id, target_user_id, result_data, bot)
                    else:
                        await send_generation_results(
                            bot, message_recipient, target_user_id, image_paths, duration, aspect_ratio_key,
                            generation_type, model_key, state, admin_user_id if is_admin_generation else None
                        )
                    
                    logger.info(f"üéØ PixelPie_AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è user_id={target_user_id}: "
                               f"{len(image_paths)} —Ñ–æ—Ç–æ –∑–∞ {duration:.1f} —Å–µ–∫")
                    asyncio.create_task(cleanup_files(image_paths + [user_data.get('photo_path')]))
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è user_id={target_user_id}: {e}", exc_info=True)
                    error_message = escape_md("‚ùå –û—à–∏–±–∫–∞! –ü–µ—á–µ–Ω—å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –Ω–∞ –±–∞–ª–∞–Ω—Å.", version=2)
                    if isinstance(generation_message, Message):
                        try:
                            await generation_message.edit_text(
                                error_message,
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                        except:
                            await send_message_with_fallback(
                                bot, message_recipient,
                                error_message,
                                reply_markup=await create_main_menu_keyboard(message_recipient),
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                    else:
                        await send_message_with_fallback(
                            bot, message_recipient,
                            error_message,
                            reply_markup=await create_main_menu_keyboard(message_recipient),
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                    if not is_admin_generation:
                        await update_user_credits(target_user_id, "increment_photo", amount=required_photos)
                        logger.info(f"–§–æ—Ç–æ –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –¥–ª—è user_id={target_user_id}")
                    await reset_generation_context(state, generation_type)
                finally:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
                    if preserved_data:
                        await state.update_data(**preserved_data)
                    await clean_admin_context(state)
                    logger.info("–ê–¥–º–∏–Ω—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
                    user_data = await state.get_data()
                    logger.info(f"–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: user_data={user_data}")

async def send_generation_results(bot: Bot, message_recipient: int, target_user_id: int, 
                                image_paths: List[str], duration: float, aspect_ratio: str, 
                                generation_type: str, model_key: str, state: FSMContext, 
                                admin_user_id: int = None) -> None:
    
    user_data = await state.get_data()
    state_value = user_data.get('state')
    logger.debug(f"send_generation_results –≤—ã–∑–≤–∞–Ω –¥–ª—è user_id={message_recipient}, image_paths={image_paths}, state={state_value}")
    
    try:
        if len(image_paths) == 1:
            caption = escape_md(f"üì∏ –í–∞—à–∞ –ò–ò –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≥–æ—Ç–æ–≤–∞! –í—Ä–µ–º—è: {duration:.1f} —Å–µ–∫", version=2)
            photo_file = FSInputFile(path=image_paths[0])
            await send_photo_with_retry(
                bot, message_recipient, photo_file, caption=caption,
                reply_markup=await create_rating_keyboard(generation_type, model_key, message_recipient, bot),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            if admin_user_id and admin_user_id != message_recipient:
                await bot.send_photo(
                    chat_id=admin_user_id,
                    photo=photo_file,
                    caption=escape_md(f"–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ —Ñ–æ—Ç–æ –¥–ª—è ID {target_user_id}", version=2),
                    reply_markup=InlineKeyboardMarkup(inline_keyboard=[[
                        InlineKeyboardButton(text="üîô –ö –¥–µ–π—Å—Ç–≤–∏—è–º", callback_data=f"user_actions_{target_user_id}")
                    ]]),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
        else:
            caption = escape_md(
                f"üì∏ {len(image_paths)} –≤–∞—à–∏—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å–æ–∑–¥–∞–Ω—ã! ({duration:.1f} —Å–µ–∫)\n"
                f"üéØ –°–¥–µ–ª–∞–Ω–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ PixelPie_AI", version=2
            )
            media = []
            for i, path in enumerate(image_paths):
                photo_file = FSInputFile(path=path)
                if i == 0:
                    media.append(InputMediaPhoto(media=photo_file, caption=caption, parse_mode=ParseMode.MARKDOWN_V2))
                else:
                    media.append(InputMediaPhoto(media=photo_file))
            await send_media_group_with_retry(bot, message_recipient, media)
            await send_message_with_fallback(
                bot, message_recipient,
                escape_md("‚≠ê –û—Ü–µ–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ò–ò —Ñ–æ—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:", version=2),
                reply_markup=await create_rating_keyboard(generation_type, model_key, message_recipient, bot),
                parse_mode=ParseMode.MARKDOWN_V2
            )
            if admin_user_id and admin_user_id != message_recipient:
                await send_media_group_with_retry(bot, admin_user_id, media)
                await bot.send_message(
                    chat_id=admin_user_id,
                    text=escape_md(f"–§–æ—Ç–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {target_user_id} –≥–æ—Ç–æ–≤—ã", version=2),
                    reply_markup=InlineKeyboardMarkup(inline_keyboard=[[
                        InlineKeyboardButton(text="üîô –ö –¥–µ–π—Å—Ç–≤–∏—è–º", callback_data=f"user_actions_{target_user_id}")
                    ]]),
                    parse_mode=ParseMode.MARKDOWN_V2
                )
        await state.clear()
        if state_value:
            await state.update_data(state=state_value)
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–ª—è user_id={message_recipient}, state={state_value}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ send_generation_results –¥–ª—è user_id={message_recipient}: {e}", exc_info=True)
        await send_message_with_fallback(
            bot, message_recipient,
            escape_md("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @AXIDI_Help", version=2),
            reply_markup=await create_main_menu_keyboard(message_recipient),
            parse_mode=ParseMode.MARKDOWN_V2
        )

async def cleanup_files(filepaths: List[Optional[str]]):
    
    for filepath in filepaths:
        if filepath and os.path.exists(filepath):
            try:
                async with file_operation_semaphore:
                    await asyncio.get_event_loop().run_in_executor(None, os.remove, filepath)
                logger.debug(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {filepath}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {filepath}: {e}")

async def run_replicate_model_async(model_id: str, input_params: dict) -> List[str]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏ Replicate —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    @tenacity.retry(
        wait=tenacity.wait_exponential(multiplier=1, min=2, max=10),
        stop=tenacity.stop_after_attempt(3),
        retry=tenacity.retry_if_exception_type(ReplicateError),
        reraise=True
    )
    async def _run():
        loop = asyncio.get_event_loop()
        replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —É–ª—å—Ç—Ä–∞-—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –º–æ–¥–µ–ª–∏ {model_id}")
        logger.debug(f"üì∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {input_params}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ—Å—Ç—å
        for key, value in input_params.items():
            if asyncio.iscoroutine(value):
                logger.error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ—Å–µ—Ä–µ–∞–ª–∏–∑—É–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä {key}: coroutine")
                raise ValueError(f"–ü–∞—Ä–∞–º–µ—Ç—Ä {key} —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—É—Ç–∏–Ω–æ–π: {value}")
            if not isinstance(value, (str, int, float, bool, list, dict, type(None))):
                logger.error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ—Å–µ—Ä–µ–∞–ª–∏–∑—É–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä {key}: —Ç–∏–ø {type(value)}")
                raise ValueError(f"–ü–∞—Ä–∞–º–µ—Ç—Ä {key} –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø: {type(value)}")
        
        output = await loop.run_in_executor(
            None,
            lambda: replicate_client.run(model_id, input=input_params)
        )
        image_urls = []
        if isinstance(output, list):
            for item in output:
                if isinstance(item, str):
                    image_urls.append(item)
                elif hasattr(item, 'url'):
                    image_urls.append(item.url)
        logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_urls}")
        return image_urls
    
    return await _run()

async def upload_image_to_replicate(photo_path: str) -> str:
    
    async with replicate_semaphore:
        loop = asyncio.get_event_loop()
        if not os.path.exists(photo_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {photo_path}")
        file_size = os.path.getsize(photo_path)
        if file_size > MAX_FILE_SIZE_BYTES:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size / 1024 / 1024:.2f} MB")
        replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)
        def upload_sync():
            with open(photo_path, 'rb') as f:
                return replicate_client.files.create(file=f)
        file_response = await loop.run_in_executor(None, upload_sync)
        image_url = file_response.urls.get('get')
        if not image_url:
            raise ValueError("Replicate –Ω–µ –≤–µ—Ä–Ω—É–ª URL")
        logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {image_url}")
        return image_url

def is_new_fast_flux_model(model_id: str, model_version: str = None) -> bool:
    
    if model_id and ("fastnew" in model_id.lower() or "fast-flux" in model_id.lower()):
        return True
    if model_version and len(model_version) == 64 and all(c in '0123456789abcdef' for c in model_version.lower()):
        return True
    if model_id and REPLICATE_USERNAME_OR_ORG_NAME and model_id.startswith(f"{REPLICATE_USERNAME_OR_ORG_NAME}/"):
        return True
    return False

# –ü—Å–µ–≤–¥–æ–Ω–∏–º—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
process_prompt = process_prompt_async
upload_image_to_replicate = upload_image_to_replicate

ADDITIONAL_PROFESSIONAL_MODELS = [
    "prithivMLmods/Flux-Skin-Real",
    "renderartist/colorgrading",
    "alvdansen/frosting_lane_flux",
    "prithivMLmods/Flux-Dev-Real-Anime",
    "gokaygokay/Flux-Portrait-LoRA",
    "XLabs-AI/flux-RealismLora",
    "ostris/flux-dev-photorealism",
    "multimodalart/flux-lora-the-explorer",
    "prithivMLmods/Flux-Realistic-People",
    "prithivMLmods/Flux-BetterSkin-LoRA"
]

PHOTOREALISM_TIPS = {
    "guidance_scale": {
        "range": "3.5-4.5",
        "optimal": "4.0",
        "note": "–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–∑–¥–∞–µ—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å"
    },
    "inference_steps": {
        "range": "45-50",
        "optimal": "50",
        "note": "–ë–æ–ª—å—à–µ —à–∞–≥–æ–≤ = –ª—É—á—à–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è"
    },
    "lora_strengths": {
        "skin_texture": "0.8-0.9 (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ)",
        "anti_cgi": "0.4-0.6 (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)",
        "face_realism": "0.7-0.8",
        "color_grading": "0.5-0.7"
    },
    "critical_prompts": [
        "natural skin texture with visible pores",
        "realistic skin tone", 
        "not CGI, not 3D render",
        "real person",
        "authentic human features",
        "professional photography",
        "DSLR camera quality"
    ],
    "avoid_prompts": [
        "perfect skin",
        "flawless",
        "smooth skin", 
        "artificial",
        "digital art",
        "rendered"
    ]
}

logger.info("üéØ –£–õ–¨–¢–†–ê-–†–ï–ê–õ–ò–°–¢–ò–ß–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ó–ê–ì–†–£–ñ–ï–ù–ê!")
logger.info("üì∏ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ LoRA –¥–ª—è –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–π –∫–æ–∂–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω—ã")
logger.info("üö´ –ê–Ω—Ç–∏-CGI —Ñ–∏–ª—å—Ç—Ä—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã") 
logger.info("‚ö° –ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")